{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PageRank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NULabTMN/cs6200-hw2/blob/main/PageRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2QKFIlR6HCY"
      },
      "source": [
        "# PageRank\n",
        "\n",
        "In this assignment, you will compute PageRank on a collection of 469,235 web sites using the iterative version of the PageRank algorithm described in class for sparse graphs (NOT the power method with explicit matrix multiplication).\n",
        "\n",
        "Consider the following directed graph:\n",
        "\n",
        "![A directed link graph](https://ccs.neu.edu/home/dasmith/courses/cs6200/pagerank.jpg)\n",
        "\n",
        "We can represent this graph as a collection of nodes, here, ordered pairs of node index and node name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_Mxj5pXKPl"
      },
      "source": [
        "small_nodes = [(0, 'A'),\n",
        "              (1, 'B'),\n",
        "              (2, 'C'),\n",
        "              (3, 'D'),\n",
        "              (4, 'E'),\n",
        "              (5, 'F')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTF3JKtTYxiZ"
      },
      "source": [
        "and a collection of directed links, i.e., ordered pairs from source to target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0V5ueOYDDN"
      },
      "source": [
        "small_edges = [\n",
        "  (0, 1),\n",
        "  (0, 2),\n",
        "  (0, 5),\n",
        "  (1, 2),\n",
        "  (1, 3),\n",
        "  (1, 4),\n",
        "  (1, 5),\n",
        "  (2, 3),\n",
        "  (2, 4),\n",
        "  (3, 0),\n",
        "  (3, 2),\n",
        "  (3, 4),\n",
        "  (3, 5),\n",
        "  (4, 0),\n",
        "  (5, 0),\n",
        "  (5, 1),\n",
        "  (5, 4)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBVDeszXY4B_"
      },
      "source": [
        "We use integer identifiers for the nodes for efficiency. Note that, unlike this example, in a real web graph, not every page will have in-links, nor will every page have out-links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPNsTGSsEwMX"
      },
      "source": [
        "## First Implementation and Test\n",
        "\n",
        "\\[10 points\\] Implement the iterative PageRank algorithm. Test your code on the six-node example using the input representation given above.  Be sure that your code handles pages that have no in-links or out-links properly.  (You may wish to test on a few such examples.) In later parts of this assignment, depending on how you store the data, it may be convenient to use iterators rather than storing the data in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMu_WaDA55sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0a168b-6bf2-4944-b7e9-0830b15dd46d"
      },
      "source": [
        ",# TODO: Implement PageRank, given nodes and edges, to start with a uniform\n",
        "# distribution over nodes, run a fixed number of iterations, and\n",
        "# return a distribution over nodes.\n",
        "from collections import defaultdict\n",
        "\n",
        "def page_rank_iter(nodes, edges, iterations=10):\n",
        "  I = [] #initializes values of all vertices to 1/len(small_nodes)\n",
        "  R = [0]*len(small_nodes)\n",
        "  a = 0.15 #value of lambda from the book.\n",
        "  for i in range(len(small_nodes)):\n",
        "    I.append(1/len(small_nodes))\n",
        "  #dictionary containing the links that point to a specific vertex/page\n",
        "  dict_ = defaultdict(list)\n",
        "  for i in small_edges:\n",
        "    dict_[i[1]].append(i[0])\n",
        "  #dictionary counting a count of outgoing links for each vertex. \n",
        "  dict_2 = {}\n",
        "  for i in small_nodes:\n",
        "    dict_2[i[0]] = 0\n",
        "  for i in small_edges:\n",
        "    dict_2[i[0]] += 1\n",
        "  while iterations >= 1: #page rank calculatations start here. \n",
        "    for i in range(len(small_nodes)):\n",
        "      R[i] = a/len(small_nodes)\n",
        "    c = 0\n",
        "    for i in small_nodes:\n",
        "      if dict_2[i[0]] == 0: #handles nodes with no out-links\n",
        "        R[c] = (R[c] + (1-a))/len(small_nodes)\n",
        "      else:\n",
        "        length = len(dict_[i[0]])\n",
        "        sum = 0\n",
        "        for j in range(length):\n",
        "          sum += I[dict_[i[0]][j]]/dict_2[dict_[i[0]][j]]\n",
        "        if sum != 0: #handles page rank for nodes with no in-links \n",
        "          R[c] = (R[c] + (1-a))*sum \n",
        "      c += 1\n",
        "    iterations -= 1\n",
        "    I = R\n",
        "  return I\n",
        "\n",
        "# Output PageRank on the toy graph at various points.\n",
        "# Make sure your output has node number, name, and PageRank value.\n",
        "\n",
        "page_rank = page_rank_iter(small_nodes, small_edges, 1)\n",
        "print(\"After 1 iteration the Pageranks are:\")\n",
        "for i in range(len(page_rank)):\n",
        "  print('Node number:', small_nodes[i][0],  'Node name: ', small_nodes[i][1],  'PageRank value: ', round(page_rank[i],3))\n",
        "#page_rank = page_rank_iter(small_nodes, small_edges, 10)\n",
        "page_rank = page_rank_iter(small_nodes, small_edges, 100)\n",
        "print(\"After 100 iterations the Pageranks are:\")\n",
        "for i in range(len(page_rank)):\n",
        "  print('Node number:', small_nodes[i][0],  'Node name: ', small_nodes[i][1],  'PageRank value: ', round(page_rank[i],3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After 1 iteration the Pageranks are:\n",
            "Node number: 0 Node name:  A PageRank value:  0.231\n",
            "Node number: 1 Node name:  B PageRank value:  0.097\n",
            "Node number: 2 Node name:  C PageRank value:  0.122\n",
            "Node number: 3 Node name:  D PageRank value:  0.109\n",
            "Node number: 4 Node name:  E PageRank value:  0.194\n",
            "Node number: 5 Node name:  F PageRank value:  0.122\n",
            "After 100 iterations the Pageranks are:\n",
            "Node number: 0 Node name:  A PageRank value:  0.035\n",
            "Node number: 1 Node name:  B PageRank value:  0.017\n",
            "Node number: 2 Node name:  C PageRank value:  0.019\n",
            "Node number: 3 Node name:  D PageRank value:  0.012\n",
            "Node number: 4 Node name:  E PageRank value:  0.022\n",
            "Node number: 5 Node name:  F PageRank value:  0.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4duRjzABB9n"
      },
      "source": [
        "## PageRank on Web Crawl Data\n",
        "\n",
        "\\[20 points\\] Download and unpack a list of `.edu` websites and the links among them from the [Common Crawl](https://commoncrawl.org/2017/05/hostgraph-2017-feb-mar-apr-crawls/) open-source web crawl. For the sake of brevity, the data record links among websites, not web pages. The information for nodes and links is the same as the toy example above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EDDdTQCd3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7976faa3-acb3-4f8a-e52e-b2be2cd422de"
      },
      "source": [
        "!wget https://ccs.neu.edu/home/dasmith/courses/cs6200/vertices-edu.txt.gz\n",
        "!gzip -df vertices-edu.txt.gz\n",
        "!wget https://ccs.neu.edu/home/dasmith/courses/cs6200/edges-edu.txt.gz\n",
        "!gzip -df edges-edu.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-24 02:10:58--  https://ccs.neu.edu/home/dasmith/courses/cs6200/vertices-edu.txt.gz\n",
            "Resolving ccs.neu.edu (ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to ccs.neu.edu (ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3703486 (3.5M) [application/x-gzip]\n",
            "Saving to: ‘vertices-edu.txt.gz’\n",
            "\n",
            "vertices-edu.txt.gz 100%[===================>]   3.53M  14.1MB/s    in 0.3s    \n",
            "\n",
            "2021-10-24 02:10:58 (14.1 MB/s) - ‘vertices-edu.txt.gz’ saved [3703486/3703486]\n",
            "\n",
            "--2021-10-24 02:10:59--  https://ccs.neu.edu/home/dasmith/courses/cs6200/edges-edu.txt.gz\n",
            "Resolving ccs.neu.edu (ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to ccs.neu.edu (ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12829526 (12M) [application/x-gzip]\n",
            "Saving to: ‘edges-edu.txt.gz’\n",
            "\n",
            "edges-edu.txt.gz    100%[===================>]  12.23M  28.5MB/s    in 0.4s    \n",
            "\n",
            "2021-10-24 02:11:00 (28.5 MB/s) - ‘edges-edu.txt.gz’ saved [12829526/12829526]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW4yp1gPUwzb"
      },
      "source": [
        "There should now be files `vertices-edu.txt` and `edges-edu.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly1t9fyjK7eC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdbe93b-fc6b-4788-8efc-74b98e934eba"
      },
      "source": [
        "# TODO: Process the raw data into the same format as the simple graph.\n",
        "# You may use a list of iterators \n",
        "vertices_ = open(\"vertices-edu.txt\")\n",
        "edges_ = open(\"edges-edu.txt\")\n",
        "\n",
        "small_nodes = []\n",
        "small_edges = []\n",
        "lines = vertices_.readlines()\n",
        "for line in lines:\n",
        "    line = line.split(' ')\n",
        "    small_nodes.append((int(line[0]), line[1]))\n",
        "print(small_nodes[:20])\n",
        "lines = edges_.readlines()\n",
        "for line in lines:\n",
        "    line = line.split(' ')\n",
        "    small_edges.append((int(line[0]), int(line[1])))\n",
        "print(small_edges[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'edu.00zl5e\\n'), (1, 'edu.06hxbt\\n'), (2, 'edu.082ifc\\n'), (3, 'edu.083mjs\\n'), (4, 'edu.09xzrr\\n'), (5, 'edu.0aoqqj\\n'), (6, 'edu.0ax4el\\n'), (7, 'edu.0c5fez\\n'), (8, 'edu.0cosn2\\n'), (9, 'edu.0dcdp8\\n'), (10, 'edu.0esfct\\n'), (11, 'edu.0jn6my\\n'), (12, 'edu.0k2wrx\\n'), (13, 'edu.0kmhdw\\n'), (14, 'edu.0n8grz\\n'), (15, 'edu.0nnoiq\\n'), (16, 'edu.0sklakwua222\\n'), (17, 'edu.0utah.art\\n'), (18, 'edu.0v1ofu\\n'), (19, 'edu.0w7zm8\\n')]\n",
            "[(386, 440), (19202, 1033), (103884, 2635), (342306, 7399), (8366, 8312), (8358, 8312), (8949, 8987), (8982, 8987), (8910, 8987), (9028, 8999), (8917, 8999), (9003, 8999), (9030, 8999), (8868, 8999), (9001, 8999), (9072, 8999), (8887, 8999), (9019, 8999), (9023, 8999), (8949, 8999)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WMf5L5VEqZb"
      },
      "source": [
        "Refine your implementation of PageRank to test for numerical convergence. Specificially, at each iteration, calculate the [perplexity](https://en.wikipedia.org/wiki/Perplexity) of the PageRank distribution, where perplexity is defined as 2 raised to the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of the PageRank distribution, i.e., $2^{H(PR)}$. (Recall that we defined entropy when talking about data compression.) The maximum perplexity of a PageRank distribution will therefore be the number of nodes in the graph.\n",
        "\n",
        "At each iteration, check the _change_ in perplexity. If the change is less than some threshold, you can stop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsL0yQKvKqAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ddd763-f4bf-40fb-e76a-4d1b279c8033"
      },
      "source": [
        "# TODO: Implement convergence testing in PageRank\n",
        "# If you choose, you can share some subroutines with your first version.\n",
        "# Print the change in perplexity at each iteration.\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "def perplexity(I): #this function calculates the perplexity\n",
        "    hpr = 0\n",
        "    for page in I:\n",
        "        hpr += page*(math.log2(page))\n",
        "    return 2**hpr\n",
        "\n",
        "def page_rank(small_nodes, small_edges, thersold = 0.00001):\n",
        "  I = [] #initializes values of all vertices to 1/len(small_nodes)\n",
        "  R = [0]*len(small_nodes)\n",
        "  a = 0.15 #value of lambda from the book.\n",
        "  perplexity_ = [0,thersold+0.00001] #initializing values so that first while loop can run\n",
        "  for i in range(len(small_nodes)):\n",
        "    I.append(1/len(small_nodes))\n",
        "  #dictionary containing in-links to a specific vertex/page\n",
        "  dict_ = defaultdict(list)\n",
        "  for i in small_edges:\n",
        "    dict_[i[1]].append(i[0])\n",
        "  #dictionary keeping a count of outgoing links for each vertex. \n",
        "  dict_2 = {}\n",
        "  for i in small_nodes:\n",
        "    dict_2[i[0]] = 0\n",
        "  for i in small_edges:\n",
        "    dict_2[i[0]] += 1\n",
        "  while perplexity_[1] - perplexity_[0] > thersold: #stop when change in perplexity drops below thersold\n",
        "    for i in range(len(small_nodes)):\n",
        "      R[i] = a/len(small_nodes)\n",
        "    c = 0\n",
        "    for i in small_nodes:\n",
        "      if dict_2[i[0]] == 0: #handles page rank for nodes with no out-links\n",
        "          R[c] = (R[c] + (1-a))/len(small_nodes)\n",
        "      else:\n",
        "        length = len(dict_[i[0]])\n",
        "        sum = 0\n",
        "        for j in range(length):\n",
        "          sum += I[dict_[i[0]][j]]/dict_2[dict_[i[0]][j]]\n",
        "        if sum != 0: #handles page rank for nodes with no in-links \n",
        "          R[c] = (R[c] + (1-a))*sum \n",
        "      c += 1\n",
        "    I = R\n",
        "    perplexity_[0] = perplexity_[1]\n",
        "    perplexity_[1] = perplexity(I)\n",
        "  return I\n",
        "\n",
        "# Output PageRank on the toy graph at various points.\n",
        "# Make sure your output has node number, name, and PageRank value.\\\n",
        "\n",
        "#print(page_rank_iter(small_nodes, small_edges, iterations=10))\n",
        "#print(page_rank_iter(small_nodes, small_edges, 1))\n",
        "#print(page_rank_iter(small_nodes, small_edges, 10))\n",
        "page_rank = page_rank(small_nodes, small_edges, 0.00001) #passing nodes, edges and thersold value\n",
        "\n",
        "for i in range(41000, 41020): #outputting page rank of some links\n",
        "  print('Node number:', small_nodes[i][0],  'Node name: ', small_nodes[i][1],  'PageRank value: ', page_rank[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node number: 41000 Node name:  edu.buffalo.groundwater\n",
            " PageRank value:  3.101093144317111e-08\n",
            "Node number: 41001 Node name:  edu.buffalo.grow\n",
            " PageRank value:  5.2624544824358514e-08\n",
            "Node number: 41002 Node name:  edu.buffalo.gsa\n",
            " PageRank value:  2.440424449580272e-07\n",
            "Node number: 41003 Node name:  edu.buffalo.gse\n",
            " PageRank value:  7.538488699330069e-07\n",
            "Node number: 41004 Node name:  edu.buffalo.gse.gsemedia\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41005 Node name:  edu.buffalo.gse.gsestudent3\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41006 Node name:  edu.buffalo.gse.gseweb\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41007 Node name:  edu.buffalo.gse.gsewebvm\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41008 Node name:  edu.buffalo.gse.gsewebwp\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41009 Node name:  edu.buffalo.gse.lis\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41010 Node name:  edu.buffalo.gse.shujaa\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41011 Node name:  edu.buffalo.haptics\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41012 Node name:  edu.buffalo.head\n",
            " PageRank value:  5.498290964561187e-08\n",
            "Node number: 41013 Node name:  edu.buffalo.health\n",
            " PageRank value:  1.427169834024688e-07\n",
            "Node number: 41014 Node name:  edu.buffalo.healtheducation\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41015 Node name:  edu.buffalo.healthinsurance\n",
            " PageRank value:  1.8114597582645132e-06\n",
            "Node number: 41016 Node name:  edu.buffalo.helpdesk\n",
            " PageRank value:  4.5655116337154554e-08\n",
            "Node number: 41017 Node name:  edu.buffalo.higher-ub\n",
            " PageRank value:  1.6058468099369124e-09\n",
            "Node number: 41018 Node name:  edu.buffalo.hireub\n",
            " PageRank value:  2.2916755593680576e-08\n",
            "Node number: 41019 Node name:  edu.buffalo.hireworkstudy\n",
            " PageRank value:  1.8114597582645132e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcncY2QHNl0M"
      },
      "source": [
        "## Link Analysis\n",
        "\n",
        "\\[20 points\\] In this final section, you will compute some properties of the web-site graph you downloaded.\n",
        "\n",
        "First, consider the _in-link count_ of a website, simply the number of web-sites pointing to it (including self-links). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_FyPlLSO2bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044c35ab-dd6c-484c-b561-d246adb2c12a"
      },
      "source": [
        "# TODO: List the document ID, domain name, and in-link count of the 50 websites with the highest in-link count\n",
        "from operator import itemgetter\n",
        "in_links = []\n",
        "for i in range(len(small_nodes)):\n",
        "  in_links.append([])\n",
        "  in_links[i].append(small_nodes[i][0])\n",
        "  in_links[i].append(small_nodes[i][1])\n",
        "  in_links[i].append(0)\n",
        "for i in small_edges:\n",
        "    in_links[i[1]][2] = in_links[i[1]][2] + 1\n",
        "in_links = sorted(in_links, key=itemgetter(2), reverse=True)\n",
        "for i in range(50): #outputting page rank of some links\n",
        "  print('Document ID:', in_links[i][0],  'Document name: ', in_links[i][1],  'In-link count: ', in_links[i][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document ID: 185524 Document name:  edu.mit.web\n",
            " In-link count:  4388\n",
            "Document ID: 278032 Document name:  edu.stanford\n",
            " In-link count:  4021\n",
            "Document ID: 244433 Document name:  edu.purdue.english.owl\n",
            " In-link count:  3531\n",
            "Document ID: 140443 Document name:  edu.indiana\n",
            " In-link count:  3339\n",
            "Document ID: 237176 Document name:  edu.princeton\n",
            " In-link count:  3251\n",
            "Document ID: 64587 Document name:  edu.columbia\n",
            " In-link count:  3123\n",
            "Document ID: 465503 Document name:  edu.yale\n",
            " In-link count:  2804\n",
            "Document ID: 418623 Document name:  edu.utexas\n",
            " In-link count:  2622\n",
            "Document ID: 383763 Document name:  edu.unc\n",
            " In-link count:  2592\n",
            "Document ID: 197698 Document name:  edu.nap\n",
            " In-link count:  2494\n",
            "Document ID: 439637 Document name:  edu.washington\n",
            " In-link count:  2291\n",
            "Document ID: 373442 Document name:  edu.umich\n",
            " In-link count:  2281\n",
            "Document ID: 440674 Document name:  edu.washington.depts\n",
            " In-link count:  2276\n",
            "Document ID: 148945 Document name:  edu.jhu.muse\n",
            " In-link count:  2255\n",
            "Document ID: 60975 Document name:  edu.colorado\n",
            " In-link count:  2232\n",
            "Document ID: 449738 Document name:  edu.wisc\n",
            " In-link count:  2230\n",
            "Document ID: 38320 Document name:  edu.bu\n",
            " In-link count:  2205\n",
            "Document ID: 83572 Document name:  edu.dartmouth\n",
            " In-link count:  1965\n",
            "Document ID: 408380 Document name:  edu.usc\n",
            " In-link count:  1952\n",
            "Document ID: 178879 Document name:  edu.mit\n",
            " In-link count:  1946\n",
            "Document ID: 27307 Document name:  edu.berkeley\n",
            " In-link count:  1908\n",
            "Document ID: 233405 Document name:  edu.pitt\n",
            " In-link count:  1857\n",
            "Document ID: 191069 Document name:  edu.msu\n",
            " In-link count:  1810\n",
            "Document ID: 326371 Document name:  edu.uchicago.press\n",
            " In-link count:  1763\n",
            "Document ID: 136464 Document name:  edu.illinois\n",
            " In-link count:  1753\n",
            "Document ID: 93874 Document name:  edu.educause\n",
            " In-link count:  1741\n",
            "Document ID: 56979 Document name:  edu.cmu.cs\n",
            " In-link count:  1730\n",
            "Document ID: 199032 Document name:  edu.ncsu\n",
            " In-link count:  1709\n",
            "Document ID: 36294 Document name:  edu.brown\n",
            " In-link count:  1702\n",
            "Document ID: 202182 Document name:  edu.nd\n",
            " In-link count:  1689\n",
            "Document ID: 68675 Document name:  edu.cornell\n",
            " In-link count:  1685\n",
            "Document ID: 71095 Document name:  edu.cornell.law\n",
            " In-link count:  1646\n",
            "Document ID: 183214 Document name:  edu.mit.mitpress\n",
            " In-link count:  1644\n",
            "Document ID: 215627 Document name:  edu.nyu\n",
            " In-link count:  1625\n",
            "Document ID: 56538 Document name:  edu.cmu\n",
            " In-link count:  1583\n",
            "Document ID: 239378 Document name:  edu.psu\n",
            " In-link count:  1541\n",
            "Document ID: 350412 Document name:  edu.ufl\n",
            " In-link count:  1533\n",
            "Document ID: 120819 Document name:  edu.harvard\n",
            " In-link count:  1529\n",
            "Document ID: 270369 Document name:  edu.si\n",
            " In-link count:  1513\n",
            "Document ID: 107916 Document name:  edu.gatech\n",
            " In-link count:  1500\n",
            "Document ID: 365396 Document name:  edu.uky\n",
            " In-link count:  1497\n",
            "Document ID: 337138 Document name:  edu.ucop\n",
            " In-link count:  1482\n",
            "Document ID: 358246 Document name:  edu.uic\n",
            " In-link count:  1472\n",
            "Document ID: 382564 Document name:  edu.umn.www1\n",
            " In-link count:  1470\n",
            "Document ID: 403069 Document name:  edu.upenn\n",
            " In-link count:  1464\n",
            "Document ID: 293521 Document name:  edu.tamu\n",
            " In-link count:  1452\n",
            "Document ID: 284517 Document name:  edu.stanford.web\n",
            " In-link count:  1451\n",
            "Document ID: 256613 Document name:  edu.rutgers\n",
            " In-link count:  1440\n",
            "Document ID: 367316 Document name:  edu.umass\n",
            " In-link count:  1430\n",
            "Document ID: 457936 Document name:  edu.wsu\n",
            " In-link count:  1419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uSlQEtmPTTA"
      },
      "source": [
        "Then, use the PageRank values compute by your second implementation. Note that some websites will have both a high in-link count and PageRank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcci2kdPlMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed176d7f-b513-441f-a2ad-12bf8c7770d7"
      },
      "source": [
        "# TODO: List the document ID, domain name, and PageRank of the 50 websites with the highest PageRank.\n",
        "highest_ranks = []\n",
        "for i in range(len(page_rank)):\n",
        "  highest_ranks.append([])\n",
        "  highest_ranks[i].append(small_nodes[i][0])\n",
        "  highest_ranks[i].append(small_nodes[i][1])\n",
        "  highest_ranks[i].append(page_rank)\n",
        "highest_ranks = sorted(highest_ranks, key=itemgetter(2), reverse=True)\n",
        "for i in range(50): #outputting page rank of some links\n",
        "  print('Document ID:', highest_ranks[i][0],  'Document name: ', highest_ranks[i][1],  \"Pagerank: \", highest_ranks[i][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxODBxL_Pyy2"
      },
      "source": [
        "Finally, compute some summary statistics on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD4bq6AyQIsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4654d20-718f-4cb3-b5af-8067e19005a0"
      },
      "source": [
        "# TODO: Compute:\n",
        "# - the proportion of websites with no in-links (i.e., source nodes);\n",
        "dict_ = defaultdict(list)\n",
        "for i in small_edges:\n",
        "  dict_[i[1]].append(i[0])\n",
        "c = 0\n",
        "for i in small_nodes:\n",
        "  if i[0] not in dict_.keys():\n",
        "    c += 1\n",
        "print(\"Proportion of websites with no in-links: \",round(c/len(small_nodes),3))\n",
        "\n",
        "# - the proportion of websites with no out-links (i.e., sink nodes);\n",
        "dict_2 = {}\n",
        "for i in small_nodes:\n",
        "  dict_2[i[0]] = 0\n",
        "for i in small_edges:\n",
        "  dict_2[i[0]] += 1\n",
        "c= 0\n",
        "for key in dict_2:\n",
        "    if dict_2[key] == 0:\n",
        "        c = c + 1 \n",
        "print(\"Proportion of websites with no out-links: \",round(c/len(small_nodes),3))\n",
        "\n",
        "# - the proportion of websites whose PageRank is higher than the initial uniform distribution.\n",
        "intial_distribution = 1/len(small_nodes)\n",
        "c - 0\n",
        "for i in page_rank:\n",
        "  if i > intial_distribution:\n",
        "    c += 1\n",
        "print(\"Proportion of websites whose PageRank is higher than the initial uniform distribution: \",round(c/len(small_nodes),3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of websites with no in-links:  0.262\n",
            "Proportion of websites with no out-links:  0.611\n",
            "Proportion of websites whose PageRank is higher than the initial uniform distribution:  0.617\n"
          ]
        }
      ]
    }
  ]
}